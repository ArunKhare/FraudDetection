{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\arunk\\\\FraudDetection'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\arunk\\FraudDetection\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fraudDetection.utils import read_yaml, create_directories\n",
    "from pathlib import Path\n",
    "from fraudDetection.constants import *\n",
    "\n",
    "from fraudDetection.logger import logging\n",
    "os.chdir(r\"C:\\Users\\arunk\\FraudDetection\")\n",
    "\n",
    "path = Path(r\"configs/config.yaml\")\n",
    "\n",
    "config_info = read_yaml(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fraudDetection.config.configuration import ConfigurationManager\n",
    "config_info = ConfigurationManager(CONFIG_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fraudDetection.config.configuration import DataIngestionConfig\n",
    "from fraudDetection.exception import FraudDetectionException\n",
    "data_ingestion_config=config_info.get_data_ingestion_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts\\data_ingestion\\2023-04-14-13-30-40\\ingested_data\n"
     ]
    }
   ],
   "source": [
    "print(data_ingestion_config.ingested_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('artifacts/data_ingestion/2023-04-14-13-30-40/raw_data')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ingestion_config.raw_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('artifacts/data_ingestion/2023-04-14-13-30-40/test')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ingestion_config.ingested_test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "online-payments-fraud-detection-dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "string = \"kaggle datasets download -d rupakroy/online-payments-fraud-detection-dataset\"\n",
    "\n",
    "filename = os.path.basename(string.split()[-1])\n",
    "\n",
    "print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rupakroy/online-payments-fraud-detection-dataset'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from fraudDetection.utils import create_directories ,read_yaml\n",
    "from fraudDetection.entity import DataIngestionConfig\n",
    "from fraudDetection.config.configuration import ConfigurationManager\n",
    "cm = ConfigurationManager(CONFIG_FILE_PATH)\n",
    "training_config = cm.get_training_pipeline_config()\n",
    "root_dir = training_config.artifacts_root\n",
    "config_info = read_yaml(CONFIG_FILE_PATH)\n",
    "config = config_info[DATA_INGESTION_CONFIG_KEY]\n",
    "raw_data_dir = Path(os.path.join(root_dir,config[DATA_INGESTION_RAW_DATA_DIR_KEY]))\n",
    "\n",
    "# data_ingestion_config = DataIngestionConfig(\n",
    "#     raw_data_dir= Path(os.path.join(root_dir,config[DATA_INGESTION_RAW_DATA_DIR_KEY])),\n",
    "#     ingested_dir=config[DATA_INGESTION_INGESTED_DIR_KEY],\n",
    "#     ingested_test_dir=config[DATA_INGESTION_TRAIN_DIR_KEY],\n",
    "#     ingested_train_dir=config[DATA_INGESTION_TRAIN_DIR_KEY],\n",
    "#     unzip_dir=config[DATA_INGESTION_UNZIP_DIR_KEY],\n",
    "#     source_url=config[DATA_INGESTION_URL_KEY]\n",
    "# )\n",
    "dataset_name = \"rupakroy/online-payments-fraud-detection-dataset\"\n",
    "\n",
    "tgz_file_path = os.path.join(raw_data_dir, dataset_name + \".zip\")\n",
    "create_directories([tgz_file_path])\n",
    "if not os.path.exists(tgz_file_path):\n",
    "    os.system(f'kaggle datasets download -d {dataset_name} -p \"{tgz_file_path}\"')\n",
    "    shutil.move(os.path.join(tgz_file_path, dataset_name + \".zip\"), tgz_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraudDetection.entity.config_entity.DataIngestionConfig"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_ingestion_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from fraudDetection.components.data_ingestion import DataIngestion\n",
    "from fraudDetection.config.configuration import ConfigurationManager\n",
    "from fraudDetection.entity import DataIngestionConfig, DataIngestionArtifact\n",
    "from pathlib import Path\n",
    "import os \n",
    "os.chdir(r\"C:\\Users\\arunk\\FraudDetection\")\n",
    "\n",
    "CONFIG_FILE_PATH = Path(\"configs\\config.yaml\")\n",
    "raw_data_dir = Path(r\"C:\\Users\\arunk\\FraudDetection\\artifacts\\data_ingestion\\raw_data\")\n",
    "config = ConfigurationManager(CONFIG_FILE_PATH)\n",
    "data_ingestion_config = config.get_data_ingestion_config()\n",
    "config = DataIngestion(data_ingestion_config)\n",
    "file = Path(\"artifacts\\data_ingestion\\zip_data\\online-payments-fraud-detection-dataset.zip\")\n",
    "\n",
    "with ZipFile(file=file,mode='r') as zip_ref:\n",
    "    zip_ref.extractall(raw_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(Path(r\"C:\\Users\\arunk\\FraudDetection\\artifacts\\data_ingestion\\raw_data\\PS_20174392719_1491204439457_log.csv\"))\n",
    "import sys,os \n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from fraudDetection.exception import FraudDetectionException\n",
    "\n",
    "train_file_path = r\"C:\\Users\\arunk\\FraudDetection\\artifacts\\data_ingestion\\train\\PS_20174392719_1491204439457_log.csv\"\n",
    "test_file_path = r\"C:\\Users\\arunk\\FraudDetection\\artifacts\\data_ingestion\\test\\PS_20174392719_1491204439457_log.csv\"\n",
    "chunk_size=10000\n",
    "file_path = r\"C:\\Users\\arunk\\FraudDetection\\artifacts\\data_ingestion\\raw_data\\PS_20174392719_1491204439457_log.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "strat_train_set, strat_test_set = train_test_split(df, test_size=0.2, random_state=42, stratify=df['isFraud'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(df, file_path) -> None:\n",
    "            try:\n",
    "                for i, (index,chunk) in enumerate(df.groupby(df.index // chunk_size)):\n",
    "                    path = Path(f\"file_{i}.csv\")\n",
    "                    print(type(chunk))\n",
    "                    print(chunk)\n",
    "                    chunk_file_path: Path = Path(file_path/path)\n",
    "                    chunk.to_csv(chunk_file_path, index=False, header=i == 0)\n",
    "            except Exception as e:\n",
    "                raise FraudDetectionException(e, sys) from e\n",
    "\n",
    "save_file(strat_test_set, test_file_path)\n",
    "save_file(strat_train_set, train_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arunk\\FraudDetection\\notebook\n"
     ]
    }
   ],
   "source": [
    "from fraudDetection.utils import create_directories\n",
    "import os\n",
    "from pathlib import Path\n",
    "print(os.getcwd())\n",
    "path = Path(\"./testingpath/mypath/subpath\")\n",
    "create_directories([path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "0    1270881\n",
      "1       1643\n",
      "Name: isFraud, dtype: int64 /n <class 'pandas.core.series.Series'>\n",
      "Training set class proportions:\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "\n",
      "Test set class proportions:\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "The class proportions are proportional.\n"
     ]
    }
   ],
   "source": [
    "def check_class_balance():\n",
    "\n",
    "    # compute class proportions in the training set\n",
    "    train_counts = strat_train_set['isFraud'].value_counts()\n",
    "    train_proportions = train_counts / len(strat_train_set)\n",
    "\n",
    "    # compute class proportions in the test set\n",
    "    test_counts = strat_test_set['isFraud'].value_counts()\n",
    "    print(type(test_counts))\n",
    "    test_proportions = test_counts / len(strat_test_set)\n",
    "    print(test_counts,\"/n\",type(test_proportions))\n",
    "    # print the class proportions\n",
    "    print('Training set class proportions:')\n",
    "    print(train_proportions)\n",
    "    print()\n",
    "    print('Test set class proportions:')\n",
    "    print(test_proportions)\n",
    "\n",
    "    # check if the class proportions are proportional\n",
    "    if abs(train_proportions[0] - test_proportions[0]) <= 0.05 and abs(train_proportions[1] - test_proportions[1]) <= 0.05:\n",
    "        print('The class proportions are proportional.')\n",
    "    else:\n",
    "        print('The class proportions are not proportional.')\n",
    "check_class_balance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200     100\n",
      "2000    200\n",
      "300     300\n",
      "400     400\n",
      "700     500\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200      20.0\n",
       "2000     40.0\n",
       "300      60.0\n",
       "400      80.0\n",
       "700     100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.Series([100,200,300,400,500],[200,2000,300,400,700])\n",
    "print(series)\n",
    "series/len(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>166.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66.666667</td>\n",
       "      <td>666.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>233.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1           2           3           4\n",
       "0  33.333333   66.666667  100.000000  133.333333  166.666667\n",
       "1  66.666667  666.666667  100.000000  133.333333  233.333333\n",
       "2   3.333333   13.333333   16.666667   30.000000   26.666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ([100,200,300,400,500],[200,2000,300,400,700],[10,40,50,90,80])\n",
    "df =pd.DataFrame(t)\n",
    "df/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\arunk\\FraudDetection\")\n",
    "from fraudDetection.utils import read_yaml\n",
    "from pathlib import Path\n",
    "schema_file_path = Path(r\"configs\\schema.yaml\")\n",
    "\n",
    "schema = read_yaml(schema_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float64'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = schema.keys()\n",
    "keys = schema.columns\n",
    "keys.amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\arunk\\FraudDetection\")\n",
    "test_file_path = Path(r\"artifacts\\data_ingestion\\test\\file_0.csv\")\n",
    "train_file_path= Path(r\"artifacts\\data_ingestion\\train\\file_0.csv\")\n",
    "\n",
    "test_df= pd.read_csv(test_file_path)\n",
    "train_df = pd.read_csv(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes.equals(test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate all  the files in the train and test directory and convert them to dataframe\n",
    "train_file_dir = Path(r\"C:\\Users\\arunk\\FraudDetection\\artifacts\\data_ingestion\\train\")\n",
    "test_file_dir = Path(r\"C:\\Users\\arunk\\FraudDetection\\artifacts\\data_ingestion\\test\")\n",
    "train_files= os.listdir(train_file_dir)[:2]\n",
    "test_files = os.listdir(test_file_dir)[:2]\n",
    "\n",
    "#number of files in each test and train dir\n",
    "num_files_train = len([f for f in train_files if os.path.isfile(os.path.join(train_file_dir, f)) if f.endswith('.csv')])\n",
    "num_files_test = len([f for f in test_files if os.path.isfile(os.path.join(test_file_dir, f)) if f.endswith('.csv')])\n",
    "\n",
    "def concat_csv_files(files: list, file_dir: str) -> pd.DataFrame:\n",
    "    dfs =[]    \n",
    "    for i, file in enumerate(files):\n",
    "        if file.endswith('.csv'):\n",
    "            path = os.path.join(file_dir,file)\n",
    "            df = pd.read_csv(path)\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "train_df = concat_csv_files(train_files,train_file_dir)\n",
    "test_df = concat_csv_files(test_files,test_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step                int64\n",
       "type               object\n",
       "amount            float64\n",
       "nameOrig           object\n",
       "oldbalanceOrg     float64\n",
       "newbalanceOrig    float64\n",
       "nameDest           object\n",
       "oldbalanceDest    float64\n",
       "newbalanceDest    float64\n",
       "isFraud             int64\n",
       "isFlaggedFraud      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fraudDetection.utils import read_yaml\n",
    "schema_keys = read_yaml(Path(r\"configs\\schema.yaml\"))\n",
    "column_schema = schema_keys[\"columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns are present in the DataFrame schema and have the expected data types.\n"
     ]
    }
   ],
   "source": [
    "missing_cols = [col for col in column_schema if col not in train_df.columns]\n",
    "mismatch_dtype_cols = [col for col, dtype in column_schema.items() if col in train_df.columns and train_df[col].dtype !=dtype]\n",
    "if missing_cols:\n",
    "    raise Exception (f\"The following columns are missing from the DataFrame schema: {missing_cols}\")\n",
    "elif mismatch_dtype_cols:\n",
    "    raise Exception (f\"The following columns data types does not match: {mismatch_dtype_cols}\")\n",
    "else:\n",
    "    print(\"All columns are present in the DataFrame schema and have the expected data types.\")\n",
    "    logging.info(f\"train test file schema are as per the Schema {column_schema}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigBox({'columns': {'step': 'int64', 'type': 'object', 'amount': 'float64', 'oldbalanceOrg': 'float64', 'newbalanceOrig': 'float64', 'oldbalanceDest': 'float64', 'newbalanceDest': 'float64', 'isFraud': 'int64'}, 'categorical_columns': ['type'], 'numerical_columns': ['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'], 'target_column': ['isFraud']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if len(train_df.columns) != len(column_series):\n",
    "    train_df = train_df.loc[:,column_schema]\n",
    "    test_df = test_df.loc[:,column_schema]\n",
    "\n",
    "if train_df.dtypes.equals(column_series):\n",
    "    print(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "step                int64\n",
       "type               object\n",
       "amount            float64\n",
       "nameOrig           object\n",
       "oldbalanceOrg     float64\n",
       "newbalanceOrig    float64\n",
       "nameDest           object\n",
       "oldbalanceDest    float64\n",
       "newbalanceDest    float64\n",
       "isFraud             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_df.columns))\n",
    "print(len(column_series))\n",
    "column_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_df.isnull().sum() / len(test_df)) * 100\n",
    "50/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "if train_df.isnull().sum().sum() > 0:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
